{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e75cbacf-589d-4e63-a88f-a950cf06dd38",
   "metadata": {},
   "source": [
    "### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb9a827-32da-4fe8-a0e1-02b673ccdc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchtext.datasets import IMDB\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from transformers import XLNetTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265a436f-255f-41e4-b9d8-68d44e21c655",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1822db7e-7daa-4edc-8c86-3c8fc6ba847c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\torchdata\\datapipes\\__init__.py:18: UserWarning: \n",
      "################################################################################\n",
      "WARNING!\n",
      "The 'datapipes', 'dataloader2' modules are deprecated and will be removed in a\n",
      "future torchdata release! Please see https://github.com/pytorch/data/issues/1196\n",
      "to learn more and leave feedback.\n",
      "################################################################################\n",
      "\n",
      "  deprecation_warning()\n"
     ]
    }
   ],
   "source": [
    "train_iter,valid_iter=IMDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "793912c8-95ad-40c9-a873-6c28906d29b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\combining.py:337: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
      "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_iter))\n",
    "next(iter(train_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f93e77-dc3c-4cc0-90f4-31a4672c6907",
   "metadata": {},
   "source": [
    "### Loading XLNetTokenizer and building vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "258a98ff-a3fa-4e6f-b1e1-7ef256f47deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
    "def yield_tokens(train_iter):\n",
    "    for _,data_sample in train_iter:\n",
    "            yield tokenizer.tokenize(data_sample)\n",
    "vocab=build_vocab_from_iterator(yield_tokens(train_iter),specials=[\"<unk>\",\"<pad>\",'<|endoftext|>'],special_first=True)\n",
    "vocab.set_default_index(vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97270dfa-40e7-46ab-b6cb-1de9d6e1df14",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_string=vocab.get_itos()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be504598-fbf2-4a04-97f8-4564efea15a5",
   "metadata": {},
   "source": [
    "### Making of DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20e565ee-a63a-4c2a-a5d8-ba5c8f9f7eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Indices: [19, 1525, 19, 9566, 658, 6872, 9990, 3714, 22, 453]\n",
      "Target Indices: [1525, 19, 9566, 658, 6872, 9990, 3714, 22, 453, 4556]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 519, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 508, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 400, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 368, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 455, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 602, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\rajve\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\rajve\\AppData\\Local\\Temp\\ipykernel_27736\\4171860680.py\", line 39, in <module>\n",
      "    src_tensor = torch.tensor(src_indices, dtype=torch.long)\n",
      "C:\\Users\\rajve\\AppData\\Local\\Temp\\ipykernel_27736\\4171860680.py:39: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  src_tensor = torch.tensor(src_indices, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import torch\n",
    "\n",
    "# 1. Final get_sample function\n",
    "def get_sample(block_size, tokens_list):\n",
    "    random_start = 0\n",
    "    stop = block_size\n",
    "    \n",
    "    # Slicing tokens\n",
    "    src_sequence = tokens_list[random_start:stop]\n",
    "    tgt_sequence = tokens_list[random_start + 1:stop + 1]\n",
    "    \n",
    "    # List conversion to avoid attribute errors and maintain alignment\n",
    "    src_sequence = list(src_sequence)\n",
    "    tgt_sequence = list(tgt_sequence)\n",
    "    \n",
    "    # Padding if target is short\n",
    "    if len(tgt_sequence) < len(src_sequence):\n",
    "        tgt_sequence.append('<|endoftext|>')\n",
    "        \n",
    "    return src_sequence, tgt_sequence\n",
    "\n",
    "# 2. Final implementation logic\n",
    "# train_iter se ek sample nikalna\n",
    "label, text = next(iter(train_iter))\n",
    "\n",
    "# IMPORTANT: .tokenize() use karein, sirf tokenizer(text) nahi\n",
    "tokens = tokenizer.tokenize(text)\n",
    "\n",
    "# Sequence generate karein\n",
    "block_size = 10\n",
    "src_text, tgt_text = get_sample(block_size, tokens)\n",
    "\n",
    "# 3. Numericalization (Ab error nahi aayega kyunki ye list of strings hai)\n",
    "src_indices = vocab(src_text)\n",
    "tgt_indices = vocab(tgt_text)\n",
    "\n",
    "# 4. Convert to Tensors\n",
    "src_tensor = torch.tensor(src_indices, dtype=torch.long)\n",
    "tgt_tensor = torch.tensor(tgt_indices, dtype=torch.long)\n",
    "\n",
    "print(f\"Source Indices: {src_indices}\")\n",
    "print(f\"Target Indices: {tgt_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c1e5588-3203-47c6-bb2d-1ae4a2aea405",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=1\n",
    "\n",
    "batch_of_tokens=[]\n",
    "\n",
    "for i in range(BATCH_SIZE):\n",
    "  _,text =next(iter(train_iter))\n",
    "  batch_of_tokens.append(tokenizer(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "555ea38a-673f-433b-a783-ace84060282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=batch_of_tokens[0][0:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78a52fbd-db03-409b-86cc-aef83d0d6451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0:\n",
      "Source Sequence (Text): ['input_ids', 'token_type_ids', 'attention_mask']\n",
      "Source Sequence (Indices): [0, 0, 0]\n",
      "Source Sequence (Shape): torch.Size([3])\n",
      "Target Sequence (Text): ['input_ids', 'token_type_ids', 'attention_mask']\n",
      "Target Sequence (Indices): [0, 0, 0]\n",
      "Target Sequence (Shape): torch.Size([3])\n",
      "Sample 1:\n",
      "Source Sequence (Text): ['input_ids', 'token_type_ids', 'attention_mask']\n",
      "Source Sequence (Indices): [0, 0, 0]\n",
      "Source Sequence (Shape): torch.Size([3])\n",
      "Target Sequence (Text): ['input_ids', 'token_type_ids', 'attention_mask']\n",
      "Target Sequence (Indices): [0, 0, 0]\n",
      "Target Sequence (Shape): torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty lists to store source and target sequences\n",
    "src_batch, tgt_batch = [], []\n",
    "\n",
    "# Define the batch size\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "# Loop to create batches of source and target sequences\n",
    "for i in range(BATCH_SIZE):\n",
    "    # Retrieve the next data point from the training iterator\n",
    "    _,text = next(iter(train_iter))\n",
    "\n",
    "    # Generate source and target sequences using the get_sample function\n",
    "    src_sequence_text, tgt_sequence_text = get_sample(block_size, tokenizer(text))\n",
    "\n",
    "    # Convert source and target sequences to tokenized vocabulary indices\n",
    "    src_sequence_indices = vocab(src_sequence_text)\n",
    "    tgt_sequence_indices = vocab(tgt_sequence_text)\n",
    "\n",
    "    # Convert the sequences to PyTorch tensors with dtype int64\n",
    "    src_sequence = torch.tensor(src_sequence_indices, dtype=torch.int64)\n",
    "    tgt_sequence = torch.tensor(tgt_sequence_indices, dtype=torch.int64)\n",
    "\n",
    "    # Append the source and target sequences to their respective batches\n",
    "    src_batch.append(src_sequence)\n",
    "    tgt_batch.append(tgt_sequence)\n",
    "\n",
    "    # Print the output for every 2nd sample (adjust as needed)\n",
    "    print(f\"Sample {i}:\")\n",
    "    print(\"Source Sequence (Text):\", src_sequence_text)\n",
    "    print(\"Source Sequence (Indices):\", src_sequence_indices)\n",
    "    print(\"Source Sequence (Shape):\", src_sequence.shape)\n",
    "    print(\"Target Sequence (Text):\", tgt_sequence_text)\n",
    "    print(\"Target Sequence (Indices):\", tgt_sequence_indices)\n",
    "    print(\"Target Sequence (Shape):\", tgt_sequence.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "329b519d-001c-40a7-865f-b4e2b2e96030",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLOCK_SIZE=30\n",
    "def collate_batch(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for _,_textt in batch:\n",
    "      src_sequence,tgt_sequence=get_sample(BLOCK_SIZE,tokenizer(_textt))\n",
    "      src_sequence=vocab(src_sequence)\n",
    "      tgt_sequence=vocab(tgt_sequence)\n",
    "      src_sequence= torch.tensor(src_sequence, dtype=torch.int64)\n",
    "      tgt_sequence = torch.tensor(tgt_sequence, dtype=torch.int64)\n",
    "      src_batch.append(src_sequence)\n",
    "      tgt_batch.append(tgt_sequence)\n",
    "\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX, batch_first=False)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX, batch_first=False)\n",
    "\n",
    "    return src_batch.to(DEVICE), tgt_batch.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d72de1a-d836-45e7-b1bd-ced163fb2705",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=1\n",
    "train_dataloader=DataLoader(train_iter,batch_size=BATCH_SIZE,shuffle=True,collate_fn=collate_batch)\n",
    "valid_dataloader=DataLoader(valid_iter,batch_size=BATCH_SIZE,shuffle=True,collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371f0755-d395-4dd5-8a7f-53bc219fa0a3",
   "metadata": {},
   "source": [
    "### Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b336b145-76af-49de-b1da-e6805c9602c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mask(size):\n",
    "    mask=torch.tril((torch.ones(size,size))==1)\n",
    "    mask=mask.float().masked_fill(mask==0,float('-inf')).masked_fill(mask==1,float(0.0))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52bdac9d-4d8c-461d-96ef-04726fc14443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(src):\n",
    "    seq_len=src.shape[0]\n",
    "    src_mask=generate_mask(seq_len)\n",
    "    src_padding_mask=(src==vocab(\"<pad>\")).transpose(0,1)\n",
    "    return src_mask,src_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3756c86-628e-4820-9be5-8b709fe9cb0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_env)",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
